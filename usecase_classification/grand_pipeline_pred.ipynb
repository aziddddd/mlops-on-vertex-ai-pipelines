{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## First Time Installation\n",
    "\n",
    "Install the latest version of Vertex SDK for Python. First time in instance only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install $USER google-cloud-aiplatform==1.15.1 --upgrade\n",
    "# ! pip3 install $USER google-cloud-bigquery==2.34.4 --upgrade\n",
    "# ! pip3 install $USER google-cloud-bigquery-storage==2.13.2 --upgrade\n",
    "# ! pip3 install $USER google-cloud-storage==1.44.0 --upgrade\n",
    "# ! pip3 install $USER kfp==1.8.13 --upgrade\n",
    "# ! pip3 install $USER google-cloud-pipeline-components==1.0.14 --upgrade\n",
    "# ! pip3 install $USER icecream==2.1.1 --upgrade\n",
    "# ! pip3 install $USER pandas-gbq==0.15.0 --upgrade\n",
    "# ! pip3 install $USER google-cloud-secret-manager --upgrade\n",
    "# ! pip3 install $USER google-cloud-pubsub==2.13.4 --upgrade\n",
    "\n",
    "# import os\n",
    "# if not os.getenv(\"IS_TESTING\"):\n",
    "#     # Automatically restart kernel after installs\n",
    "#     import IPython\n",
    "\n",
    "#     app = IPython.Application.instance()\n",
    "#     app.kernel.do_shutdown(True)\n",
    "\n",
    "# # Check versions\n",
    "# ! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "# ! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load your pipeline components and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Related Python packages\n",
    "from icecream import ic\n",
    "from kfp.v2 import dsl\n",
    "\n",
    "# Components\n",
    "from ml_components.dataimport import (\n",
    "    get_rundates,\n",
    "    get_period,\n",
    "    get_import_query,\n",
    "    bq_query_no_return,\n",
    "    bq_query_to_dataframe,\n",
    "    get_previous_dataset_from_model_league,\n",
    "    \n",
    ")\n",
    "from ml_components.datacheck import (\n",
    "    printing,\n",
    "    grand_drift_check,\n",
    ")\n",
    "from ml_components.datapreproc import (\n",
    "    data_preprocess,\n",
    ")\n",
    "from ml_components.modelling import (\n",
    "    get_champion_model,\n",
    ")\n",
    "from ml_components.prediction import (\n",
    "    model_predictor,\n",
    ")\n",
    "from ml_components.outbound import (\n",
    "    generate_bq_table_from_gsc,\n",
    "    update_model_league,\n",
    "    export_prediction,\n",
    ")\n",
    "from ml_components.alert import (\n",
    "    push_slack_notification,\n",
    ")\n",
    "from ml_components.pipelinehelper import (\n",
    "    func_op,\n",
    "    save_pipeline,\n",
    "    run_pipeline,\n",
    ")\n",
    "\n",
    "# Configs\n",
    "from config import (\n",
    "    SERVICE_ACCOUNT,\n",
    "    PROJECT_ID,\n",
    "    REGION,\n",
    "    RUNNER,\n",
    "    PIPELINE_NAME,\n",
    "    BUCKET_NAME,\n",
    "    PRED_PIPELINE_ROOT as PIPELINE_ROOT,\n",
    "    USE_VAIEXP,\n",
    "    PARAMETER_VALUES,\n",
    "    parameter_checks\n",
    ")\n",
    "parameter_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your pipeline\n",
    "```\n",
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def your_pipeline(\n",
    "    parameter_value: data_type,\n",
    "):\n",
    "    ops_1 = func_op(\n",
    "        func=function,\n",
    "        _component_human_name='your ops 1 label',\n",
    "        base_image='python:3.7', #optional\n",
    "        function_arg=parameter_value,\n",
    "    )\n",
    "    \n",
    "    ops_2 = func_op(\n",
    "        func=function,\n",
    "        _component_human_name='your ops 2 label',\n",
    "        packages_to_install=[\n",
    "            'pandas==1.3.3'\n",
    "        ],\n",
    "        function_arg=ops_1.outputs['output'],\n",
    "    )\n",
    "```\n",
    "\n",
    "#### Choose your desired GCP pre-built image for your node(s)\n",
    "- https://cloud.google.com/deep-learning-containers/docs/choosing-container\n",
    "- `! gcloud container images list --repository=\"gcr.io/deeplearning-platform-release\"`\n",
    "- You can also just choose 'python:3.x' if want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def grand_pipeline(\n",
    "    bucket_name: str,\n",
    "    project_id: str,\n",
    "    project_name: str,\n",
    "    region: str,\n",
    "    job_id: str,\n",
    "    run_date: str,\n",
    "    seed: int,\n",
    "    train_size: float,\n",
    "    target_column: str,\n",
    "    drop_columns: str,\n",
    "    auto_balance: str,\n",
    "    feature_importance_dict_str: str,\n",
    "    numerical_drift_partition_threshold: float,\n",
    "    numerical_importance_partition_threshold: float,\n",
    "    categorical_drift_partition_threshold: float,\n",
    "    categorical_importance_partition_threshold: float,\n",
    "    category_threshold: int,\n",
    "    delta: int,\n",
    "    model_params: str,\n",
    "    is_endpoint: bool,\n",
    "    mlops_topic: str,\n",
    "    runner: str,\n",
    "    commit_short_sha: str,\n",
    "):\n",
    "    ########################################################################################################################\n",
    "    ########################################################################################################################\n",
    "    ################################################### Ops Declaration ####################################################\n",
    "    ########################################################################################################################\n",
    "    ########################################################################################################################\n",
    "\n",
    "    \n",
    "    ###########################################################\n",
    "    ######################### Rundate #########################\n",
    "    ###########################################################\n",
    "\n",
    "    rundates_op = func_op(\n",
    "        func=get_rundates,\n",
    "        _component_human_name='get_rundates',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=['pandas==1.3.3'],\n",
    "        run_date=run_date,\n",
    "    )\n",
    "\n",
    "    usage_run_date = rundates_op.outputs['usage_run_date']\n",
    "    src_run_dt = rundates_op.outputs['src_run_dt']\n",
    "\n",
    "    ###########################################################\n",
    "    ####################### Import Data #######################\n",
    "    ###########################################################\n",
    "\n",
    "    period_op = func_op(\n",
    "        func=get_period,\n",
    "        _component_human_name='get_period',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=['pandas==1.3.3'],\n",
    "        run_date=usage_run_date,\n",
    "    )\n",
    "\n",
    "    # Get queries\n",
    "    import_pred_data_query_op = func_op(\n",
    "        func=get_import_query,\n",
    "        _component_human_name='get_pred_import_query',\n",
    "        base_image='python:3.7',\n",
    "        datestr=period_op.outputs['pred_dt'],\n",
    "    )\n",
    "\n",
    "    # Get previous datasets using model league\n",
    "    prev_pred_dataset_op = func_op(\n",
    "        func=get_previous_dataset_from_model_league,\n",
    "        _component_human_name='get_prev_pred_dataset',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=['pandas-gbq==0.15.0'],\n",
    "        cpu_limit='2',\n",
    "        memory_limit='32G',\n",
    "        project_id=project_id,\n",
    "        project_name=project_name,\n",
    "        dataset_type='pred',\n",
    "        runner=runner,\n",
    "        location=region,\n",
    "    )\n",
    "\n",
    "    # Get datasets using queries\n",
    "    pred_dataset_op = func_op(\n",
    "        func=bq_query_to_dataframe,\n",
    "        _component_human_name='get_pred_dataset',\n",
    "        base_image='python:3.7',\n",
    "        project_id=project_id,\n",
    "        cpu_limit='2',\n",
    "        memory_limit='32G',\n",
    "        query=import_pred_data_query_op.outputs['query'],\n",
    "    )\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #################### Data Preprocessing ###################\n",
    "    ###########################################################\n",
    "\n",
    "    pred_data_preprocess_op = func_op(\n",
    "        func=data_preprocess,\n",
    "        _component_human_name='pred_data_preprocess',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=['pandas==1.3.3'],\n",
    "        cpu_limit='4',\n",
    "        memory_limit='32G',\n",
    "        bucket_name=bucket_name,\n",
    "        category_threshold=category_threshold,\n",
    "        drop_columns=drop_columns,\n",
    "        target_column=target_column,\n",
    "        dataset=pred_dataset_op.outputs['dataset'],\n",
    "    )\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    #################### Data Drift Check #####################\n",
    "    ###########################################################\n",
    "\n",
    "    pred_drift_check_op = func_op(\n",
    "        func=grand_drift_check,\n",
    "        _component_human_name='pred_drift_check',\n",
    "        base_image='gcr.io/deeplearning-platform-release/sklearn-cpu',\n",
    "        cpu_limit='4',\n",
    "        memory_limit='32G',\n",
    "        bucket_name=bucket_name,\n",
    "        src_run_dt=src_run_dt,\n",
    "        project_name=project_name,\n",
    "        dataset_p=pred_data_preprocess_op.outputs['processed_dataset'],\n",
    "        dataset_q=prev_pred_dataset_op.outputs['previous_dataset'],\n",
    "        feature_importance_dict_str=feature_importance_dict_str,\n",
    "        numerical_drift_partition_threshold=numerical_drift_partition_threshold,\n",
    "        numerical_importance_partition_threshold=numerical_importance_partition_threshold,\n",
    "        categorical_drift_partition_threshold=categorical_drift_partition_threshold,\n",
    "        categorical_importance_partition_threshold=categorical_importance_partition_threshold,\n",
    "        category_threshold=category_threshold,\n",
    "        delta=delta,\n",
    "        mode='pred',\n",
    "    )\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    ####################### Prediction ########################\n",
    "    ###########################################################\n",
    "\n",
    "    model_champion_op = func_op(\n",
    "        func=get_champion_model,\n",
    "        _component_human_name='get_champion_model',\n",
    "        base_image='gcr.io/deeplearning-platform-release/sklearn-cpu',\n",
    "        packages_to_install=[\n",
    "            'xgboost',\n",
    "            'pandas-gbq==0.15.0',\n",
    "        ],\n",
    "        project_id=project_id,\n",
    "        project_name=project_name,\n",
    "        runner=runner,\n",
    "        location=region,\n",
    "    )\n",
    "\n",
    "    model_predictor_op = func_op(\n",
    "        func=model_predictor,\n",
    "        _component_human_name='model_predictor',\n",
    "        base_image='gcr.io/deeplearning-platform-release/sklearn-cpu',\n",
    "        packages_to_install=[\n",
    "            'xgboost',\n",
    "        ],\n",
    "        cpu_limit='4',\n",
    "        memory_limit='32G',\n",
    "        target_column=target_column,\n",
    "        model_champion_object=model_champion_op.outputs['model_champion_object'],\n",
    "        processed_dataset=pred_data_preprocess_op.outputs['processed_dataset'],\n",
    "    )\n",
    "\n",
    "    ###########################################################\n",
    "    ######################## Outbound #########################\n",
    "    ###########################################################\n",
    "\n",
    "    prediction_dataset_to_bq_op = func_op(\n",
    "        func=generate_bq_table_from_gsc,\n",
    "        _component_human_name='prediction_dataset_to_bq',\n",
    "        base_image='python:3.7',\n",
    "        cpu_limit='4',\n",
    "        memory_limit='32G',\n",
    "        retry=3,\n",
    "        project_id=project_id,\n",
    "        project_name=project_name,\n",
    "        dataset_id='MLOPS_PREDICTION_DATASET',\n",
    "        runner=runner,\n",
    "        table_name='prediction',\n",
    "        src_run_dt=src_run_dt,\n",
    "        dataset_format='PARQUET',\n",
    "        location=region,\n",
    "        dataset_to_save=model_predictor_op.outputs['prediction_dataset'],\n",
    "    )\n",
    "\n",
    "    pred_update_model_league_op = func_op(\n",
    "        func=update_model_league,\n",
    "        _component_human_name='pred_update_model_league',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=['pandas-gbq==0.15.0'],\n",
    "        cpu_limit='4',\n",
    "        memory_limit='16G',\n",
    "        project_id=project_id,\n",
    "        project_name=project_name,\n",
    "        location=region,\n",
    "        job_id=job_id,\n",
    "        src_run_dt=src_run_dt,\n",
    "        bq_path=prediction_dataset_to_bq_op.outputs['bq_path'],\n",
    "        choose_model='champion',\n",
    "        runner=runner,\n",
    "        commit_short_sha=commit_short_sha,\n",
    "        is_cold_start=model_champion_op.outputs['is_cold_start'],\n",
    "        is_endpoint=is_endpoint,\n",
    "        mlops_topic=mlops_topic,\n",
    "        update_mode='pred',\n",
    "        model_object=model_champion_op.outputs['model_champion_object'],\n",
    "    )\n",
    "\n",
    "    export_prediction_op = func_op(\n",
    "        func=export_prediction,\n",
    "        _component_human_name='export_prediction',\n",
    "        base_image='python:3.7',\n",
    "        packages_to_install=[\n",
    "            'pandas',\n",
    "            'pandas-gbq==0.15.0',\n",
    "        ],\n",
    "        project_id=project_id,\n",
    "        runner=runner,\n",
    "        prediction_dataset=model_predictor_op.outputs['prediction_dataset'],\n",
    "    )\n",
    "\n",
    "    # ########################\n",
    "    # #### Failing points ####\n",
    "    # ########################\n",
    "\n",
    "    # with dsl.Condition(\n",
    "    #     data_check_result_op.outputs['alert_msg'] != '',\n",
    "    #     name=\"failing_point_1\"\n",
    "    # ):\n",
    "    #     data_quality_check_result_fail_op = func_op(\n",
    "    #         func=push_slack_notification,\n",
    "    #         _component_human_name='data_quality_check_result_fail',\n",
    "    #         base_image='python:3.7',\n",
    "    #         packages_to_install=['google-cloud-secret-manager'],\n",
    "    #         job_id=job_id,\n",
    "    #         src_run_dt=src_run_dt,\n",
    "    #         text=data_check_result_op.outputs['alert_msg'],\n",
    "    #         channel='#your-project-name-internal',\n",
    "    #         webhook_config_str=webhook_config,\n",
    "    #         runner=runner,\n",
    "    #     )\n",
    "\n",
    "\n",
    "    ########################################################################################################################\n",
    "    ########################################################################################################################\n",
    "    ##################################################### Ops Caching ######################################################\n",
    "    ########################################################################################################################\n",
    "    ########################################################################################################################\n",
    "\n",
    "    nodes_no_cache = [\n",
    "        rundates_op,\n",
    "\n",
    "#         period_op,\n",
    "#         import_pred_data_query_op,\n",
    "\n",
    "#         pred_dataset_op,\n",
    "#         pred_data_preprocess_op,\n",
    "\n",
    "        prev_pred_dataset_op,\n",
    "\n",
    "#         pred_drift_check_op,\n",
    "\n",
    "#         data_check_result_op,\n",
    "\n",
    "        model_champion_op,\n",
    "\n",
    "#         model_predictor_op,\n",
    "\n",
    "#         export_prediction_op,\n",
    "        pred_update_model_league_op\n",
    "    ]\n",
    "    \n",
    "    if nodes_no_cache:\n",
    "        for node in nodes_no_cache:\n",
    "            node.set_caching_options(enable_caching=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_PATH, JOB_ID, DISPLAY_NAME = save_pipeline(\n",
    "    pipeline=grand_pipeline,\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    mode='pred',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your pipeline locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(\n",
    "    project_id=PROJECT_ID,\n",
    "    staging_bucket=BUCKET_NAME,\n",
    "    location=REGION,\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=TEMPLATE_PATH,\n",
    "    job_id=JOB_ID,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    service_account=SERVICE_ACCOUNT,\n",
    "    parameter_values=PARAMETER_VALUES,\n",
    "    # enable_caching=False,\n",
    "    use_vaiexp=USE_VAIEXP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lightweight_functions_component_io_kfp.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
